name: Cross-Platform Test Matrix

on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches: [main, develop]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

env:
  AI_FAILURE_ANALYSIS: true

jobs:
  test-matrix:
    name: Test (${{ matrix.os }}, ${{ matrix.runtime }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30

    strategy:
      fail-fast: false
      max-parallel: 6
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        runtime: ['18', '20']
        include:
          - os: ubuntu-latest
            runtime: '18'
            coverage: true
        exclude:
          - os: macos-latest
            runtime: '16'

    steps:
      - uses: actions/checkout@v4

      - name: Setup Runtime
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.runtime }}
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Run Tests
        id: test
        run: npm test
        continue-on-error: true

      - name: Generate Coverage
        if: matrix.coverage == true && steps.test.outcome == 'success'
        run: npm run coverage

      - name: Upload Coverage
        if: matrix.coverage == true
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/coverage-final.json
        continue-on-error: true

      - name: Collect Test Results
        if: always()
        run: |
          echo "test_status=${{ steps.test.outcome }}" >> $GITHUB_OUTPUT
          echo "os=${{ matrix.os }}" >> $GITHUB_OUTPUT
          echo "runtime=${{ matrix.runtime }}" >> $GITHUB_OUTPUT

  aggregate-results:
    name: Aggregate Test Results
    needs: test-matrix
    if: always()
    runs-on: [self-hosted, linux, ai-agent]

    steps:
      - name: Setup AI Agent Environment
        uses: ./.github/actions/setup-ai-agent

      - name: Analyze Failures
        if: env.AI_FAILURE_ANALYSIS == 'true'
        run: |
          echo "ðŸ¤– Analyzing test failures with AI..."

          # This would aggregate failure data and analyze patterns
          bash .github/scripts/ai-analyze-test-failures.sh
        env:
          AI_API_KEY: ${{ secrets.AI_API_KEY }}
        continue-on-error: true

      - name: Post Results
        if: github.event_name == 'pull_request'
        run: |
          gh pr comment ${{ github.event.pull_request.number }} \
            --body "## âœ… Cross-Platform Tests Complete

          All test matrix jobs have completed. Check individual job logs for details."
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        continue-on-error: true
